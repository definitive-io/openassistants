<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>OpenAssistants Blog</title>
        <link>https://definitive-io.github.io/openassistants/blog</link>
        <description>OpenAssistants Blog</description>
        <lastBuildDate>Tue, 19 Dec 2023 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The Smart Path: How RAG and Guardrails Power Domain-Specific AI]]></title>
            <link>https://definitive-io.github.io/openassistants/blog/rag-and-guardrails</link>
            <guid>https://definitive-io.github.io/openassistants/blog/rag-and-guardrails</guid>
            <pubDate>Tue, 19 Dec 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[The integration of AI chatbots into customer service showcase technological advancement, yet they present unique challenges. A vivid example comes from a chatbot deployed at a Chevrolet dealership in Watsonville, which encountered an unusual request for a Python script to solve fluid dynamics equations. This incident highlights the necessity for precise AI applications, an area where OpenAssistants’ platform excels with its Retrieval-Augmented Generation (RAG) and guardrail features.]]></description>
            <content:encoded><![CDATA[<p>The integration of AI chatbots into customer service showcase technological advancement, yet they present unique challenges. A vivid example comes from a chatbot deployed at a Chevrolet dealership in Watsonville, which encountered an unusual request for a Python script to solve fluid dynamics equations. This incident highlights the necessity for precise AI applications, an area where OpenAssistants’ platform excels with its Retrieval-Augmented Generation (RAG) and guardrail features.</p>
<img src="https://definitive-io.github.io/openassistants/img/chevy_watsonville.jpeg" style="max-width:400px;width:100%">
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="domain-specific-ai-through-rag">Domain-Specific AI Through RAG<a href="https://definitive-io.github.io/openassistants/blog/rag-and-guardrails#domain-specific-ai-through-rag" class="hash-link" aria-label="Direct link to Domain-Specific AI Through RAG" title="Direct link to Domain-Specific AI Through RAG">​</a></h2>
<p>OpenAssistants leverages RAG to ensure chatbots operate within their designated domains. RAG integration allows a Chevrolet dealership's chatbot to access solely automotive-related information, avoiding off-topic interactions and ensuring domain relevance.</p>
<p><img loading="lazy" alt="Chatbot interaction focused on automotive queries" src="https://definitive-io.github.io/openassistants/assets/images/img1-dc7224a6843ef356253e9c2e5681b919.png" width="1374" height="1466" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="structuring-interactions-with-guardrails">Structuring Interactions with Guardrails<a href="https://definitive-io.github.io/openassistants/blog/rag-and-guardrails#structuring-interactions-with-guardrails" class="hash-link" aria-label="Direct link to Structuring Interactions with Guardrails" title="Direct link to Structuring Interactions with Guardrails">​</a></h2>
<p>OpenAssistants’ guardrails direct user interactions by steering conversations with relevant prompts. This not only streamlines communication but also ensures the chatbot's exchanges remain focused on the dealership's services.</p>
<p><img loading="lazy" alt="Structured chatbot prompts guiding the user" src="https://definitive-io.github.io/openassistants/assets/images/oa_chevy2-ab93af120dfefc8e8439b0198ea09aaa.png" width="1636" height="1488" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="consistent-and-accurate-responses">Consistent and Accurate Responses<a href="https://definitive-io.github.io/openassistants/blog/rag-and-guardrails#consistent-and-accurate-responses" class="hash-link" aria-label="Direct link to Consistent and Accurate Responses" title="Direct link to Consistent and Accurate Responses">​</a></h2>
<p>RAG's retrieval-based approach means the chatbot consistently provides reliable information. It draws from a validated knowledge base, eliminating the risks of generating erroneous responses and maintaining consistency across all interactions.</p>
<p><img loading="lazy" alt="Chatbot providing consistent, reliable information" src="https://definitive-io.github.io/openassistants/assets/images/oa_chevy3-80bab6c0ff65b5046e3ffd4a9852dbf5.png" width="1648" height="1498" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="enhanced-efficiency-with-low-latency">Enhanced Efficiency with Low Latency<a href="https://definitive-io.github.io/openassistants/blog/rag-and-guardrails#enhanced-efficiency-with-low-latency" class="hash-link" aria-label="Direct link to Enhanced Efficiency with Low Latency" title="Direct link to Enhanced Efficiency with Low Latency">​</a></h2>
<p>OpenAssistants optimizes AI chatbots for rapid response times. Focusing on information retrieval rather than generation significantly reduces response latency, boosting customer service speed and efficiency.</p>
<p>The Chevrolet dealership scenario highlights how an unrefined AI can yield problematic results. By incorporating RAG and building guardrails, OpenAssistants transforms chatbots into powerful, domain-specific tools, advancing AI-powered workflows across industries.</p>]]></content:encoded>
            <category>openassisstants</category>
            <category>ai</category>
            <category>rag</category>
            <category>guardrails</category>
            <category>llm</category>
        </item>
        <item>
            <title><![CDATA[Assistants not Agents]]></title>
            <link>https://definitive-io.github.io/openassistants/blog/assistants-not-agents</link>
            <guid>https://definitive-io.github.io/openassistants/blog/assistants-not-agents</guid>
            <pubDate>Fri, 08 Dec 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[In the fast-evolving world of AI systems, the distinction between building AI assistants and autonomous agents has become crucial. Recent insights from Dharmesh Shah highlight the inherent challenges with AI agents and why a more focused approach is preferable.]]></description>
            <content:encoded><![CDATA[<p>In the fast-evolving world of AI systems, the distinction between building AI assistants and autonomous agents has become crucial. Recent insights from <a href="https://agent.ai/p/why-most-agent-ais-dont-work-yet" target="_blank" rel="noopener noreferrer">Dharmesh Shah</a> highlight the inherent challenges with AI agents and why a more focused approach is preferable.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="the-pitfall-of-autonomous-agents">The Pitfall of Autonomous Agents<a href="https://definitive-io.github.io/openassistants/blog/assistants-not-agents#the-pitfall-of-autonomous-agents" class="hash-link" aria-label="Direct link to The Pitfall of Autonomous Agents" title="Direct link to The Pitfall of Autonomous Agents">​</a></h4>
<p>AI agents, like those in projects such as AutoGPT and BabyAGI, are designed to function autonomously, handling a series of tasks without human intervention. This sounds ideal, but there's a catch. These agents rely on imperfect Large Language Models (LLMs) like GPT to interpret goals and execute tasks. While LLMs are incredibly advanced, they're not infallible. They have an inherent error rate, which might seem negligible at a glance but can significantly impact an agent's performance.</p>
<p>For instance, if an LLM has a 95% success rate for each task, the cumulative success rate drops alarmingly with each additional task an agent undertakes. The mathematics behind this shows that even with a high individual task success rate, the overall reliability of an agent can diminish rapidly, reducing its effectiveness to a mere coin toss in complex scenarios. This is particularly problematic for general-purpose agents trying to cater to diverse functions.</p>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">AI agents like that are also prone to all kinds of disastrous security holes that aren't nearly as harmful to copilots - I think that's a major reason we haven't seen a breakout application of that form of agent yet, whereas copilots are being used successfully on a daily basis</p>— Simon Willison (@simonw) <a href="https://twitter.com/simonw/status/1733916061928686040?ref_src=twsrc%5Etfw">December 10, 2023</a></blockquote>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="the-advantage-of-ai-assistants">The Advantage of AI Assistants<a href="https://definitive-io.github.io/openassistants/blog/assistants-not-agents#the-advantage-of-ai-assistants" class="hash-link" aria-label="Direct link to The Advantage of AI Assistants" title="Direct link to The Advantage of AI Assistants">​</a></h4>
<p>This is where AI assistants come into the limelight. Unlike their autonomous counterparts, AI assistants are designed to perform specific tasks, one at a time, with human interaction playing a central role. This approach has several advantages:</p>
<ol>
<li>
<p><strong>Reduced Error Rate</strong>: By focusing on specific tasks, AI assistants can minimize the cumulative error rate. A narrower scope means less room for errors to compound.</p>
</li>
<li>
<p><strong>Human Oversight</strong>: AI assistants can work in tandem with humans, allowing for real-time feedback and corrections. This not only ensures more accurate outcomes but also helps in refining the AI's learning process.</p>
</li>
<li>
<p><strong>Specialized Functionality</strong>: Tailoring an AI assistant to specific use-cases means it can be optimized for those tasks, resulting in a more efficient and effective performance.</p>
</li>
<li>
<p><strong>Flexibility and Control</strong>: With AI assistants, users maintain control, dictating the pace and direction of the task. This leads to a more user-friendly experience, as the assistant can adapt to the user's needs and preferences.</p>
</li>
</ol>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="launching-openassistants">Launching <code>OpenAssistants</code><a href="https://definitive-io.github.io/openassistants/blog/assistants-not-agents#launching-openassistants" class="hash-link" aria-label="Direct link to launching-openassistants" title="Direct link to launching-openassistants">​</a></h4>
<p>That's where <code>openassistants</code> comes in. We aim to make it easier to develop robust assistants that rely on function calling for performing actions and retrieving information into a conversational context. With a human in the loop these systems can be <em>useful</em> and <em>reliable</em>. Our goal is to make the process of building robust assistants as easy as possible by putting as much boilerplate and common components into a set of extensible and composible libraries.</p>
<p>We're launching with three packages:</p>
<ul>
<li><code>openassistants</code> the core library responsible for the main function calling / message generating runtime</li>
<li><code>openassistants-fastapi</code> a set of FastAPI routes used for interacting with the core runtime loop through a REST API</li>
<li><code>openassistants-react</code> an example chat client that supports rich streaming outputs like tables, plots, form inputs and text.</li>
</ul>
<p>The project is built on top of LangChain and we will soon support more sophisticated RAG features based on LlamaIndex. Our goal is to be the open alternative to the AssistantsAPI that can operate against any LLM: both Open Source LLMs like fine-tuned Llama's focused on function calling and proprietary models with e.g. native support for function calling.</p>
<p><img loading="lazy" src="https://github.com/definitive-io/openassistants/assets/1309307/3e7821f4-62d8-42c0-80c7-94be8b3f2e2c" alt="" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://definitive-io.github.io/openassistants/blog/assistants-not-agents#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h4>
<p>In conclusion, while the allure of fully autonomous AI agents is undeniable, the current state of technology suggests a more measured approach. Building AI assistants that excel in specific tasks and work in harmony with human users is not just practical but also more aligned with our current technological capabilities. This approach promises a more reliable AI experience that leads to experiences that we can actually deploy with confidence in production today.</p>]]></content:encoded>
            <category>openassisstants</category>
            <category>ai</category>
            <category>assistants</category>
            <category>agents</category>
            <category>llm</category>
        </item>
    </channel>
</rss>