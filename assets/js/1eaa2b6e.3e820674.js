"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[900],{6424:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"rag-and-guardrails","metadata":{"permalink":"/openassistants/blog/rag-and-guardrails","editUrl":"https://github.com/definitive-io/openassistants/blog/2023-12-19-rag-and-guardrails/index.md","source":"@site/blog/2023-12-19-rag-and-guardrails/index.md","title":"The Smart Path: How RAG and Guardrails Power Domain-Specific AI","description":"The integration of AI chatbots into customer service showcase technological advancement, yet they present unique challenges. A vivid example comes from a chatbot deployed at a Chevrolet dealership in Watsonville, which encountered an unusual request for a Python script to solve fluid dynamics equations. This incident highlights the necessity for precise AI applications, an area where OpenAssistants\u2019 platform excels with its Retrieval-Augmented Generation (RAG) and guardrail features.","date":"2023-12-19T00:00:00.000Z","formattedDate":"December 19, 2023","tags":[{"label":"openassisstants","permalink":"/openassistants/blog/tags/openassisstants"},{"label":"ai","permalink":"/openassistants/blog/tags/ai"},{"label":"rag","permalink":"/openassistants/blog/tags/rag"},{"label":"guardrails","permalink":"/openassistants/blog/tags/guardrails"},{"label":"llm","permalink":"/openassistants/blog/tags/llm"}],"readingTime":1.28,"hasTruncateMarker":false,"authors":[{"name":"Dan Loman","title":"Core contributor of OpenAssistants","url":"https://github.com/dloman118","imageURL":"https://avatars.githubusercontent.com/u/99347459?v=4","key":"dan"}],"frontMatter":{"slug":"rag-and-guardrails","title":"The Smart Path: How RAG and Guardrails Power Domain-Specific AI","authors":["dan"],"tags":["openassisstants","ai","rag","guardrails","llm"]},"unlisted":false,"nextItem":{"title":"Assistants not Agents","permalink":"/openassistants/blog/assistants-not-agents"}},"content":"The integration of AI chatbots into customer service showcase technological advancement, yet they present unique challenges. A vivid example comes from a chatbot deployed at a Chevrolet dealership in Watsonville, which encountered an unusual request for a Python script to solve fluid dynamics equations. This incident highlights the necessity for precise AI applications, an area where OpenAssistants\u2019 platform excels with its Retrieval-Augmented Generation (RAG) and guardrail features.\\n\\n<img src=\\"/openassistants/img/chevy_watsonville.jpeg\\" style={{maxWidth: \\"400px\\", width: \\"100%\\"}} />\\n\\n## Domain-Specific AI Through RAG\\n\\nOpenAssistants leverages RAG to ensure chatbots operate within their designated domains. RAG integration allows a Chevrolet dealership\'s chatbot to access solely automotive-related information, avoiding off-topic interactions and ensuring domain relevance.\\n\\n![Chatbot interaction focused on automotive queries](/img/img1.png)\\n\\n## Structuring Interactions with Guardrails\\n\\nOpenAssistants\u2019 guardrails direct user interactions by steering conversations with relevant prompts. This not only streamlines communication but also ensures the chatbot\'s exchanges remain focused on the dealership\'s services.\\n\\n![Structured chatbot prompts guiding the user](/img/oa_chevy2.png)\\n\\n## Consistent and Accurate Responses\\n\\nRAG\'s retrieval-based approach means the chatbot consistently provides reliable information. It draws from a validated knowledge base, eliminating the risks of generating erroneous responses and maintaining consistency across all interactions.\\n\\n![Chatbot providing consistent, reliable information](/img/oa_chevy3.png)\\n\\n## Enhanced Efficiency with Low Latency\\n\\nOpenAssistants optimizes AI chatbots for rapid response times. Focusing on information retrieval rather than generation significantly reduces response latency, boosting customer service speed and efficiency.\\n\\nThe Chevrolet dealership scenario highlights how an unrefined AI can yield problematic results. By incorporating RAG and building guardrails, OpenAssistants transforms chatbots into powerful, domain-specific tools, advancing AI-powered workflows across industries."},{"id":"assistants-not-agents","metadata":{"permalink":"/openassistants/blog/assistants-not-agents","editUrl":"https://github.com/definitive-io/openassistants/blog/2023-12-8-assistants-not-agents/index.md","source":"@site/blog/2023-12-8-assistants-not-agents/index.md","title":"Assistants not Agents","description":"In the fast-evolving world of AI systems, the distinction between building AI assistants and autonomous agents has become crucial. Recent insights from Dharmesh Shah highlight the inherent challenges with AI agents and why a more focused approach is preferable.","date":"2023-12-08T00:00:00.000Z","formattedDate":"December 8, 2023","tags":[{"label":"openassisstants","permalink":"/openassistants/blog/tags/openassisstants"},{"label":"ai","permalink":"/openassistants/blog/tags/ai"},{"label":"assistants","permalink":"/openassistants/blog/tags/assistants"},{"label":"agents","permalink":"/openassistants/blog/tags/agents"},{"label":"llm","permalink":"/openassistants/blog/tags/llm"}],"readingTime":3.43,"hasTruncateMarker":false,"authors":[{"name":"Rick Lamers","title":"Core contributor of OpenAssistants","url":"https://github.com/ricklamers","imageURL":"https://avatars.githubusercontent.com/u/1309307?v=4","key":"rick"},{"name":"Dan Loman","title":"Core contributor of OpenAssistants","url":"https://github.com/dloman118","imageURL":"https://avatars.githubusercontent.com/u/99347459?v=4","key":"dan"}],"frontMatter":{"slug":"assistants-not-agents","title":"Assistants not Agents","authors":["rick","dan"],"tags":["openassisstants","ai","assistants","agents","llm"]},"unlisted":false,"prevItem":{"title":"The Smart Path: How RAG and Guardrails Power Domain-Specific AI","permalink":"/openassistants/blog/rag-and-guardrails"}},"content":"In the fast-evolving world of AI systems, the distinction between building AI assistants and autonomous agents has become crucial. Recent insights from [Dharmesh Shah](https://agent.ai/p/why-most-agent-ais-dont-work-yet) highlight the inherent challenges with AI agents and why a more focused approach is preferable.\\n\\n#### The Pitfall of Autonomous Agents\\n\\nAI agents, like those in projects such as AutoGPT and BabyAGI, are designed to function autonomously, handling a series of tasks without human intervention. This sounds ideal, but there\'s a catch. These agents rely on imperfect Large Language Models (LLMs) like GPT to interpret goals and execute tasks. While LLMs are incredibly advanced, they\'re not infallible. They have an inherent error rate, which might seem negligible at a glance but can significantly impact an agent\'s performance.\\n\\nFor instance, if an LLM has a 95% success rate for each task, the cumulative success rate drops alarmingly with each additional task an agent undertakes. The mathematics behind this shows that even with a high individual task success rate, the overall reliability of an agent can diminish rapidly, reducing its effectiveness to a mere coin toss in complex scenarios. This is particularly problematic for general-purpose agents trying to cater to diverse functions.\\n\\n<blockquote class=\\"twitter-tweet\\"><p lang=\\"en\\" dir=\\"ltr\\">AI agents like that are also prone to all kinds of disastrous security holes that aren&#39;t nearly as harmful to copilots - I think that&#39;s a major reason we haven&#39;t seen a breakout application of that form of agent yet, whereas copilots are being used successfully on a daily basis</p>&mdash; Simon Willison (@simonw) <a href=\\"https://twitter.com/simonw/status/1733916061928686040?ref_src=twsrc%5Etfw\\">December 10, 2023</a></blockquote>\\n\\n#### The Advantage of AI Assistants\\n\\nThis is where AI assistants come into the limelight. Unlike their autonomous counterparts, AI assistants are designed to perform specific tasks, one at a time, with human interaction playing a central role. This approach has several advantages:\\n\\n1. **Reduced Error Rate**: By focusing on specific tasks, AI assistants can minimize the cumulative error rate. A narrower scope means less room for errors to compound.\\n\\n2. **Human Oversight**: AI assistants can work in tandem with humans, allowing for real-time feedback and corrections. This not only ensures more accurate outcomes but also helps in refining the AI\'s learning process.\\n\\n3. **Specialized Functionality**: Tailoring an AI assistant to specific use-cases means it can be optimized for those tasks, resulting in a more efficient and effective performance.\\n\\n4. **Flexibility and Control**: With AI assistants, users maintain control, dictating the pace and direction of the task. This leads to a more user-friendly experience, as the assistant can adapt to the user\'s needs and preferences.\\n\\n#### Launching `OpenAssistants`\\n\\nThat\'s where `openassistants` comes in. We aim to make it easier to develop robust assistants that rely on function calling for performing actions and retrieving information into a conversational context. With a human in the loop these systems can be _useful_ and _reliable_. Our goal is to make the process of building robust assistants as easy as possible by putting as much boilerplate and common components into a set of extensible and composible libraries.\\n\\nWe\'re launching with three packages:\\n\\n- `openassistants` the core library responsible for the main function calling / message generating runtime\\n- `openassistants-fastapi` a set of FastAPI routes used for interacting with the core runtime loop through a REST API\\n- `openassistants-react` an example chat client that supports rich streaming outputs like tables, plots, form inputs and text.\\n\\nThe project is built on top of LangChain and we will soon support more sophisticated RAG features based on LlamaIndex. Our goal is to be the open alternative to the AssistantsAPI that can operate against any LLM: both Open Source LLMs like fine-tuned Llama\'s focused on function calling and proprietary models with e.g. native support for function calling.\\n\\n![](https://github.com/definitive-io/openassistants/assets/1309307/3e7821f4-62d8-42c0-80c7-94be8b3f2e2c)\\n\\n#### Conclusion\\n\\nIn conclusion, while the allure of fully autonomous AI agents is undeniable, the current state of technology suggests a more measured approach. Building AI assistants that excel in specific tasks and work in harmony with human users is not just practical but also more aligned with our current technological capabilities. This approach promises a more reliable AI experience that leads to experiences that we can actually deploy with confidence in production today."}]}')}}]);